{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datatable as dt  # pip install datatable\n",
    "import pandas as pd # pip install pandas\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gzp(file):\n",
    "    '''\n",
    "    GZP = gzip process\n",
    "    Takes a gzipped .csv and puts it into a Pandas df, make an average (gridded)\n",
    "    '''\n",
    "    df = dt.fread(file)\n",
    "    df = df.to_pandas()\n",
    "    return df\n",
    "\n",
    "def mean_df(df, lat_width, lon_width):\n",
    "    '''\n",
    "    Receives a dataframe of clear sky radiances\n",
    "    Counts the number of radiances then stores count + avg radiances row-wise in a new df\n",
    "    '''\n",
    "    df_out = pd.DataFrame()\n",
    "    df['count'] = len(df)\n",
    "    for i in range(int(180/lat_width)):\n",
    "        lat_min = -90 + i*lat_width\n",
    "        lat_max = lat_min + lat_width\n",
    "        for j in range(int(360/lon_width)):\n",
    "            lon_min = -180 + j * lon_width\n",
    "            lon_max = lon_min + lon_width\n",
    "            ct = len(df.loc[(df['lat'] >= lat_min) & \n",
    "                           (df['lat'] < lat_max) & \n",
    "                           (df['lon'] >= lon_min) &\n",
    "                           (df['lon'] < lon_max) &\n",
    "                           (abs(df['sci']) == 2)])\n",
    "            if ct > 0:\n",
    "                df_out = pd.concat([df_out, pd.DataFrame(df.loc[(df['lat'] >= lat_min) & \n",
    "                                                               (df['lat'] < lat_max) & \n",
    "                                                               (df['lon'] >= lon_min) &\n",
    "                                                               (df['lon'] < lon_max) &\n",
    "                                                               (abs(df['sci']) == 2)].mean(numeric_only=True)).T])\n",
    "                df_out.iloc[-1].at['count'] = ct\n",
    "    return df_out\n",
    "\n",
    "def files_to_df(files):\n",
    "    '''\n",
    "    Receives: a folder\n",
    "    Returns: a dataframe of the files in that folder with separate columns for Year, Month and Day\n",
    "    '''\n",
    "    df = pd.DataFrame(data=files, columns = ['file'])\n",
    "    # Add columns that will be filled next\n",
    "    df['year'] = 0\n",
    "    df['month'] = 0\n",
    "    df['day'] = 0\n",
    "    for i in range(len(df)):\n",
    "        df.iloc[i, df.columns.get_loc('year')] = int(df['file'][i].rsplit('\\\\')[5].rsplit('_')[0])\n",
    "        df.iloc[i, df.columns.get_loc('month')] = int(df['file'][i].rsplit('\\\\')[5].rsplit('_')[1])\n",
    "        df.iloc[i, df.columns.get_loc('day')] = int(df['file'][i].rsplit('\\\\')[5].rsplit('_')[2])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify all files are readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('C:\\\\data\\\\AIRS\\\\L1b\\\\_AIRS2\\\\*.csv.gz')\n",
    "print('Found', len(files), 'files.')\n",
    "\n",
    "if 1 == 1:\n",
    "    for file in tqdm(files):\n",
    "        try:\n",
    "            df = gzp(file)\n",
    "        except:\n",
    "            print(file, 'is unreadable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate files, create single-year ~1Gb daily radiance avg for each lat*lon grid -> gzip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dff = files_to_df(files)                       # dataframe of files (dff)\n",
    "print('Found', len(files), 'files.')\n",
    "print('Found these years:', dff['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in dff['year'].unique():\n",
    "    dffs = dff.loc[dff['year'] == year]  # dataframe of files, single year (dffs)\n",
    "    dfo = pd.DataFrame()\n",
    "    print('Processing year', str(year)+'...')\n",
    "    for i in tqdm(range(len(dffs))):\n",
    "        df = pd.DataFrame()\n",
    "        df = mean_df(gzp(dffs.iloc[i]['file']), 20, 20)\n",
    "        df['year'] = dffs.iloc[i]['year']\n",
    "        df['month'] = dffs.iloc[i]['month']\n",
    "        dfo = pd.concat([dfo, df])\n",
    "    print('dfo mem size:', round(dfo.memory_usage().sum()/2**20, 0), 'MB')\n",
    "    \n",
    "    # Prepare output folder\n",
    "    save_path = 'C:\\\\data\\\\AIRS\\\\L1b\\\\_AIRS3\\\\'\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    dfo.to_csv(save_path + str(year) + '_dailyavgs.csv.gz', compression = 'gzip', index=False, header=True)\n",
    "\n",
    "# clear df's from memory\n",
    "df = pd.DataFrame()\n",
    "dfo = pd.DataFrame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
