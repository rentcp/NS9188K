{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm.auto import tqdm # library for progress bars\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "from time import strptime\n",
    "import datatable as dt\n",
    "import tarfile\n",
    "import io\n",
    "\n",
    "import gzip\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook pre-processes LBL data for convenience & rapid handling/processing in  _AIRS6 notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompress .gz files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typical input is a folder of LBL files resembling: lbl_ERA5_AIRS_L1b_v4-2003.tar.gz\n",
    "# The first time this runs, decompress the .gz into a .tar, then delete the .gz\n",
    "\n",
    "folder_LBL = 'C:\\\\data\\\\LBL\\\\res_v4\\\\'\n",
    "files = glob.glob(folder_LBL+'*.gz')\n",
    "\n",
    "# Unzip the contents of the .gz files\n",
    "if 1 == 2:\n",
    "    for file in tqdm(files):\n",
    "        with gzip.open(file, 'rb') as f_in:\n",
    "            with open(file[:-3], 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "# Delete the .gz files after decompressing\n",
    "if 1 == 2:\n",
    "    print('Deleting gzips...')\n",
    "    for item in os.listdir(folder_LBL):\n",
    "        if item.endswith(\".gz\"):\n",
    "            os.remove(os.path.join(folder_LBL, item))\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 TAR files.\n"
     ]
    }
   ],
   "source": [
    "# If multiple LBL types are in the same folder (ERA5, GHG, MET, CFC...)\n",
    "# this tag specification allows only a portion of the files to be processed\n",
    "tag = 'ERA5'\n",
    "files = glob.glob(folder_LBL+'*'+tag+'*.tar')\n",
    "print('Found', len(files), 'TAR files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open each .tar file, add each .dat file to the lgrid dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6414d3af945a41e6af8c4469167b28c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='TAR Files'), FloatProgress(value=0.0, layout=Layout(flex='2'), max=19.0), HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='DAT Files'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lgrid = pd.DataFrame(columns = np.arange(0.1, 1800.1, 0.1))  # lgrid means \"Line-by-line grid (lat x lon) of radiances\"\n",
    "lgrid[['year', 'month', 'lat', 'lon']] = []\n",
    "lgrid.set_index(['year', 'month', 'lat', 'lon'], inplace=True)\n",
    "\n",
    "for file in tqdm(files, 'TAR Files', ncols = 400, position = 0):\n",
    "    with tarfile.open(file) as tar:\n",
    "        for member in tqdm(tar, 'DAT Files', ncols = 400, position = 1, leave = False):\n",
    "            if member.isreg():      # Is it a regular file?\n",
    "                #print(\"{} - {} bytes\".format(member.name, member.size))\n",
    "                csv_file = io.StringIO(tar.extractfile(member).read().decode('ascii'))\n",
    "                df_in = pd.read_csv(csv_file, header=None, delim_whitespace=True)\n",
    "                year = int(member.name.rsplit('-')[1])\n",
    "                month = strptime(member.name.rsplit('_')[4].rsplit('-')[2],'%b').tm_mon\n",
    "                lat = int(member.name.rsplit('_')[5][3:])\n",
    "                lon = int(member.name.rsplit('_')[6][3:])\n",
    "                lgrid.loc[(year, month, lat, lon)] = df_in[1].values*1000  # convert mW --> W\n",
    "\n",
    "lgrid.sort_index(inplace=True)\n",
    "lgrid.columns = np.arange(0.1, 1800.1, 0.1).round(1)\n",
    "lgrid = lgrid.rename_axis([\"wavenumber\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degrade lgrid resolution, then save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving file...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "n=4 # Degrade LBL by a factor of 4 (i.e., 0.1, 0.2, 0.3, ...0.9 cm-1 --> 0.1 cm-1, 0.5 cm-1, 0.9 cm-1)\n",
    "\n",
    "lgridd = lgrid.T.groupby(np.arange(len(lgrid.T))//n).mean().T    #lgridd name: extra \"d\" means \"degraded\"\n",
    "lgridd.columns = np.arange(0.1, 1800.1, 0.1*n).round(3)\n",
    "\n",
    "if 1 == 1:\n",
    "    print('Saving file...')\n",
    "    lgridd.to_csv('C:\\\\data\\\\LBL\\\\lgridd_v4\\\\'+tag+'_v4.csv.gz', compression = 'gzip', index=True, header=True)\n",
    "    print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
