{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "import math\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import datatable as dt\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm # library for progress bars\n",
    "from IPython.display import clear_output # Library for live update of progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_AIRS_20x20 = '.\\\\data\\\\AIRS\\\\L1B_globe_20x20\\\\'\n",
    "folder_LBL_20x20 = '.\\\\data\\\\LBL\\\\lgridd_v4\\\\'\n",
    "folder_LBL_cfc = '.\\\\data\\\\LBL\\\\cfc\\\\'\n",
    "\n",
    "AIRS_ir = \"AIRS.2021.04.09.121.L1B.AIRS_Rad.v5.0.25.0.G21100105112.hdf\"\n",
    "AIRS_vis = \"AIRS.2021.04.09.121.L1B.VIS_Rad.v5.0.0.0.G21100104903.hdf\"\n",
    "\n",
    "wn = pd.read_csv(\"AIRS_wavenumbers.csv\", usecols=['wavenumber'])\n",
    "wn = wn.round(3)\n",
    "\n",
    "HITRAN2020 = pd.read_csv(\"HITRAN2020_CO2_620_720.txt\", delim_whitespace=True)\n",
    "HITRAN2020 = HITRAN2020[HITRAN2020.columns[:2]]\n",
    "HITRAN2020=HITRAN2020.rename(columns = {'[cm-1]':'Absorbance'})\n",
    "# Prepare easier plotting by moving exponent to Y-label\n",
    "HITRAN2020['Absorbance'] = HITRAN2020['Absorbance'] * 1E19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRS:\n",
    "rgrid = pd.DataFrame()\n",
    "print('Importing AIRS data...')\n",
    "for file in glob.glob(folder_AIRS_20x20+'*.csv.gz'):\n",
    "    rgrid = pd.concat([rgrid, pd.read_csv(file)])\n",
    "\n",
    "rgrid = rgrid.astype({'year': 'int32'})\n",
    "rgrid = rgrid.astype({'month': 'int32'})\n",
    "rgrid = rgrid.drop(['scanang', 'sci', 'sza', 'state'], axis=1).set_index(['year', 'month', 'lat', 'lon']).sort_index(ascending=True)\n",
    "print('Relabeling columns...')\n",
    "rgrid = pd.concat([rgrid.iloc[:, :1864], rgrid.iloc[:, -1]], axis=1) # drop wavenumbers higher than 1613.862\n",
    "rgrid.columns = np.append([[wn['wavenumber'][:1864].values]], [['count']]) # rename column integers with wavenumber value\n",
    "rgrid = rgrid.loc[:, :, 2:8, :] # Keep just lat's 2-8 (no arctic/antarctic)\n",
    "\n",
    "if (rgrid.values <= 0).any():\n",
    "    print(f'{round((rgrid[rgrid <= 0].count(axis=0).sum() / (rgrid.shape[0]*rgrid.shape[1]) * 100), 2)} percent of radiances are negative. Removing...')\n",
    "    rgrid = rgrid[(rgrid > 0)]\n",
    "    if (rgrid.values <= 0).any():\n",
    "        print(\"Something didn't work, there are still negative radiances\")\n",
    "\n",
    "rgrid.dropna(axis = 1, how = 'all', inplace=True) # Remove the channels with negative (now NaN) radiances\n",
    "\n",
    "year_count = rgrid.index.get_level_values(0).unique().values.max()-rgrid.index.get_level_values(0).unique().values.min() + 1\n",
    "chan_count1 = len(rgrid.columns) - 1\n",
    "spectra_count1 = rgrid['count'].sum()\n",
    "radiance_count1 = spectra_count1 * chan_count1\n",
    "print('Before filtering, there are an avg of', round(spectra_count1/1e6/year_count,2), 'million spectra per year')\n",
    "print('Before filtering, there are', round(spectra_count1/1e6, 1), 'million spectra total')\n",
    "print('Before filtering', round(radiance_count1/1e9, 1), 'billion radiances total')\n",
    "\n",
    "# Filter by measurement count\n",
    "if 1 == 1:\n",
    "    before_count = len(rgrid)\n",
    "    rgrid = rgrid.loc[(rgrid['count'] >= 5)]\n",
    "    print(f'Removing {100*round((1-len(rgrid)/before_count), 3)}% of gridcells with <5 measurements/month')\n",
    "    \n",
    "# Remove channels with insufficient length of time\n",
    "if 1 == 1:\n",
    "    rcounts = pd.DataFrame(rgrid.groupby(['lat', 'lon']).count().sum(axis=0))\n",
    "    keep_chan = rcounts.loc[rcounts[0] >= (rcounts[0].max()-0)] # can adjust record length inclusion criteria here.\n",
    "    print('Keeping %s percent of channels with full record length' %round(len(keep_chan)/len(rcounts[0])*100, 2))\n",
    "    rgrid = rgrid.loc[:, keep_chan.index.values]\n",
    "\n",
    "spectra_count2 = rgrid['count'].sum()\n",
    "rgrid = rgrid.drop(['count'], axis=1)\n",
    "rgrid.columns = rgrid.columns.astype('float')\n",
    "rgrid_ix = rgrid.drop(rgrid.columns, axis=1) # Define the AIRS index for intersecting with LBL later.\n",
    "chan_count2 = len(rgrid.columns)\n",
    "radiance_count2 = spectra_count2 * chan_count2\n",
    "print('After filtering, there are an avg of', round(spectra_count2/1e6/year_count, 2), 'million spectra per year')\n",
    "print('After filtering, there are', round(spectra_count2/1e6, 1), 'million spectra total')\n",
    "print('After filtering', round(radiance_count2/1e9, 1), 'billion radiances total')\n",
    "print('After filtering', spectra_count2*chan_count2/1E9/year_count, 'billion radiances per year, avg')\n",
    "print('AIRS Memory: %s MB' %round(rgrid.memory_usage().sum()/2**20, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(90 * 135 * 10 * 24 * 365 / 1e12 * chan_count2, 'trillion radiances/yr at 650-1620 cm-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(90 * 135 * 10 * 24 * 365 / 1e12 * 2378, 'trillion total radiances/yr (650-2600 cm-1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import LBL data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbl_import(file):\n",
    "    lbl = pd.read_csv(file)\n",
    "    lbl.set_index(['year', 'month', 'lat', 'lon'], inplace=True)\n",
    "    lbl = lbl.loc[:, :, 2:8, :] # Keep just lat's 2-8 (no arctic/antarctic)\n",
    "    lbl.columns = pd.to_numeric(lbl.columns, errors='coerce')\n",
    "    print('Done. Memory use:', round(lbl.memory_usage().sum()/2**20, 1), 'MB')\n",
    "    return lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(folder_LBL_cfc+'*.gz'):\n",
    "    print('Importing', file+\"...\")\n",
    "    if 'ERA' in file:\n",
    "        lcfc0 = lbl_import(file)\n",
    "    if 'CFC11' in file:\n",
    "        lcfc11 = lbl_import(file)\n",
    "    if 'CFC12' in file:\n",
    "        lcfc12 = lbl_import(file)\n",
    "\n",
    "for file in glob.glob(folder_LBL_20x20+'*.gz'):\n",
    "    print('Importing', file+\"...\")\n",
    "    if 'ERA' in file:\n",
    "        lgridd = lbl_import(file)\n",
    "        lgridd = pd.merge(lgridd, rgrid_ix, how='inner', on=['year', 'month', 'lat', 'lon']) # note 1\n",
    "        lgridd.columns = pd.to_numeric(lgridd.columns, errors='coerce')\n",
    "    elif 'GHG' in file:\n",
    "        lgriddg = lbl_import(file)\n",
    "        lgriddg = pd.merge(lgriddg, rgrid_ix, how='inner', on=['year', 'month', 'lat', 'lon']) # note 1\n",
    "        lgriddg.columns = pd.to_numeric(lgriddg.columns, errors='coerce')\n",
    "    elif 'MET' in file:\n",
    "        lgriddm = lbl_import(file)\n",
    "        lgriddm = pd.merge(lgriddm, rgrid_ix, how='inner', on=['year', 'month', 'lat', 'lon']) # note 1\n",
    "        lgriddm.columns = pd.to_numeric(lgriddm.columns, errors='coerce')\n",
    "        \n",
    "years = lgridd.index.get_level_values(0).unique().values.max()-lgridd.index.get_level_values(0).unique().values.min()\n",
    "\n",
    "# Note 1: If LBL is generated where there is no AIRS data, the LBL results must be removed for these locations because\n",
    "# they are spuriously high (10x) radiance where no L1b location was provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for timespan consistency between the two datasets\n",
    "print('The LBL dataset does not have these years in AIRS:', \n",
    "      [x for x in rgrid.index.get_level_values(0).unique().values if x not in lgridd.index.get_level_values(0).unique().values]\n",
    "     )\n",
    "print('The AIRS dataset does not have these years in the LBL:', \n",
    "     [x for x in lgridd.index.get_level_values(0).unique().values if x not in rgrid.index.get_level_values(0).unique().values]\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlma(df, wn):\n",
    "    '''\n",
    "    mlma = \"Make LBL match AIRS\" \n",
    "    Receives: LBL radiances and WN (the resolution index of AIRS radiances)\n",
    "    Returns: LBL radiances spaced (indexed) exactly like AIRS, with result interpolated for each channel\n",
    "    '''\n",
    "    wnl = wn['wavenumber'].values.tolist()\n",
    "    remove_list = (df.index & wn['wavenumber'].values).values.tolist()\n",
    "    for r in remove_list:\n",
    "        wnl.remove(r)\n",
    "    df = pd.concat([df, pd.DataFrame(index=wnl)])\n",
    "    df.sort_index(inplace = True)\n",
    "    df.interpolate(inplace = True)\n",
    "    #df.interpolate(method = 'nearest', inplace = True)\n",
    "    #df.interpolate(method = 'quadratic', inplace = True)\n",
    "    return df.loc[wn['wavenumber'].values]\n",
    "\n",
    "def linr(df):\n",
    "    '''\n",
    "    Receives: dataframe of annual radiances at various wavenumbers\n",
    "    Returns: dataframe of slopes from linear regression over time for each wavenumber\n",
    "    '''\n",
    "    # For upcoming loops, need lists of wavenumbers and years\n",
    "    wns = df.index.get_level_values(1).unique().values\n",
    "    years = df.xs(wns[0], axis=0, level=1).T.columns.values\n",
    "\n",
    "    # Linear regression (slopes) for each wavenumber in each lat band\n",
    "    sl = pd.DataFrame(index = wns, columns = df.columns.values) # sl == slopes\n",
    "    for wn in wns:\n",
    "        clear_output(wait=True); print(\"Linear regression:\", round(wn,0), \"of\", wns.max())\n",
    "        for lat, row in df.xs(wn, axis=0, level=1).T.iterrows():\n",
    "            sl.loc[wn].at[lat], _, _, _, _ = scipy.stats.linregress(years, row.values)\n",
    "    clear_output(wait=True); print(\"Finished.\")\n",
    "    return sl.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1 - Multipanel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhdf.SD import *\n",
    "\n",
    "def square(x, y, width, color, a):\n",
    "    from matplotlib.patches import Rectangle\n",
    "    j = matplotlib.colors.to_rgb(color)\n",
    "    #from matplotlib.patheffects import withStroke\n",
    "    sq = Rectangle((x, y), width, width, clip_on=False, zorder=10, linewidth=0.4, \n",
    "                    edgecolor=(j[0], j[1], j[2], a), facecolor=(0, 0, 0, 0))\n",
    "                    #path_effects=[withStroke(linewidth=1, foreground='w')])\n",
    "    return sq\n",
    "    \n",
    "def ir_at(y, x):\n",
    "    OLR = pd.DataFrame(list(zip(wn['wavenumber'], ir[y,x,:])), columns=['wavenumber', 'radiance'])\n",
    "    #OLR = OLR.round(3)\n",
    "    OLR = OLR.loc[OLR.radiance > 0.1]\n",
    "    OLR.set_index('wavenumber', inplace = True)\n",
    "    return OLR\n",
    "\n",
    "def image(rads):\n",
    "    YTrack = len(rads[:,0,0,0,0])\n",
    "    XTrack = len(rads[0,:,0,0,0])\n",
    "    SubTrack = len(rads[0,0,0,:,0])\n",
    "    SubXTrack = len(rads[0,0,0,0,:])\n",
    "    delta_y = 8\n",
    "    colors = [0, 1, 2]\n",
    "    df2 = {}\n",
    "\n",
    "    for color in colors:\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for y in np.arange(0,135,1):\n",
    "            y = int(y)\n",
    "            dfmid = pd.DataFrame()\n",
    "\n",
    "            for x in np.arange(0, 90, 1):\n",
    "                data_in = pd.DataFrame(data=rads[y,int(x),color,:delta_y,:], \n",
    "                                       index=np.arange(y*delta_y, (1+y)*delta_y, 1), \n",
    "                                       columns = np.arange(x*SubXTrack, (1+x)*SubXTrack, 1)\n",
    "                                      )\n",
    "                dfmid = pd.concat([dfmid, data_in], axis=1)\n",
    "\n",
    "            df = df.append(dfmid) \n",
    "\n",
    "        df = df/df.max().max() # Normalize to 1 for color assignment (0-1 RGB value)\n",
    "        df2[color] = df.sort_index().sort_index(axis=1)\n",
    "\n",
    "    df = np.dstack([df2[2]**0.85,df2[1]**0.85,df2[0]**0.85]) #dstack R, G, B dataframes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumps = [-1]\n",
    "for i in range(len(wn['wavenumber']) - 1):\n",
    "    if wn['wavenumber'][i+1] - wn['wavenumber'][i] > 15:\n",
    "        jumps.append(i)\n",
    "jumps.append(len(wn['wavenumber'])-1)\n",
    "jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = SD(AIRS_vis)\n",
    "rads = f.select('radiances')\n",
    "lats = f.select('cornerlats')\n",
    "lons = f.select('cornerlons')\n",
    "dfvis = image(rads)\n",
    "\n",
    "f = SD(AIRS_ir)\n",
    "ir = f.select('radiances')\n",
    "cld = f.select('spectral_clear_indicator')\n",
    "\n",
    "clrx = []\n",
    "clry = []\n",
    "for y in range(cld[:,:].shape[0]):\n",
    "    for x in range(cld[:,:].shape[1]):\n",
    "        if cld[y,x] == -2:\n",
    "            clrx.append(x)\n",
    "            clry.append(y)\n",
    "        elif cld[y,x] == 2:\n",
    "            clrx.append(x)\n",
    "            clry.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 4\n",
    "\n",
    "width = dfvis.shape[1]\n",
    "height = dfvis.shape[0]\n",
    "\n",
    "clrir = ir_at(clry[j], clrx[j])\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(14, 6))\n",
    "\n",
    "ax[0].imshow(dfvis, aspect = 1.0, origin = 'lower')\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "\n",
    "for j in range(len(clrx)):\n",
    "    if ((clrx[j] >= 32) & (clrx[j] <= 59)):\n",
    "        ax[0].add_artist(square(clrx[j]/90*width, clry[j]/135*height, width/110, 'yellow', 1.0))\n",
    "    else:\n",
    "        ax[0].add_artist(square(clrx[j]/90*width, clry[j]/135*height, width/110, 'yellowgreen', 0.9))\n",
    "\n",
    "for n in range(len(jumps)-3):\n",
    "    clrir.loc[slice(wn['wavenumber'][jumps[n]+1], wn['wavenumber'][jumps[n+1]])].plot(lw=0.15, c='k', ax=ax[1])\n",
    "ax[1].set_ylim([0, 165])\n",
    "ax[1].set_xlim([600, 1650])\n",
    "ax[1].minorticks_on()\n",
    "ax[1].legend().set_visible(False)\n",
    "ax[1].set_ylabel(r'Radiance, mW$\\,$m$^{-2}$(cm$^{-1}$)$^{-1}$sr$^{-1}$', fontsize=10)\n",
    "ax[1].set_xlabel(r'Wavenumber, cm$^{-1}$', fontsize=10)\n",
    "\n",
    "clrir.loc[slice(wn['wavenumber'][0], wn['wavenumber'][129])].plot(lw=0.4, c='k', ax=ax[2])\n",
    "clrir.loc[slice(wn['wavenumber'][130], wn['wavenumber'][210])].plot(lw=0.4, c='k', ax=ax[2])\n",
    "ax[2].set_ylim([-20, 80])\n",
    "ax[2].set_yticks([30, 40, 50, 60, 70, 80])\n",
    "ax[2].tick_params(axis='both', direction='out', which='both')\n",
    "ax[2].set_xlim([630, 710])\n",
    "ax[2].legend().set_visible(False)\n",
    "ax[2].set_ylabel(r'Radiance, mW$\\,$m$^{-2}$(cm$^{-1}$)$^{-1}$sr$^{-1}$', ha='left', fontsize=10)\n",
    "ax[2].set_xlabel(r'Wavenumber, cm$^{-1}$', fontsize=10)\n",
    "\n",
    "ax3 = ax[2].twinx()\n",
    "markerline, stemlines, baseline = ax3.stem(HITRAN2020['Wavenumber'], \n",
    "                                           HITRAN2020['Absorbance'], \n",
    "                                           markerfmt=' ', linefmt=\"g-\", basefmt=\"g-\", use_line_collection=True\n",
    "                                          )\n",
    "plt.setp(stemlines, 'linewidth', 0.4)\n",
    "\n",
    "ax3.set_ylim([0, 6])\n",
    "ax3.set_yticks([0, 1, 2, 3])\n",
    "ax3.minorticks_on()\n",
    "ax3.yaxis.set_tick_params(which='minor', right=False)\n",
    "ax3.set_ylabel('HITRAN Absorbance\\nx10$^{-19}$ cm$^{-1}$ mol$^{-1}$ cm$^2$', ha='right', fontsize=11, color='g')\n",
    "ax3.tick_params(axis='both', direction='out', which='both')\n",
    "\n",
    "if 1 == 2:\n",
    "    plt.savefig('.\\fig1.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate global average radiance, global change\n",
    "# Weights for computing one global average radiance:\n",
    "weights = []\n",
    "for lat in range(7):\n",
    "    weights.append(2 * np.pi * (np.sin(np.radians(70-lat*20)) - (np.sin(np.radians(70-(lat+1)*20)))) / 4 / np.pi)\n",
    "weights = weights / sum(weights)\n",
    "assert sum(weights) == 1.0, \"weights don't sum to 1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global average radiance\n",
    "globalr = (rgrid.groupby(['lat']).mean().T * weights).T.sum()\n",
    "globalr[globalr == 0] = np.nan # Where radiance = 0, replace with nan to avoid plotting\n",
    "globall = (lgridd.groupby(['lat']).mean().T * weights).T.sum()\n",
    "\n",
    "# Linregress\n",
    "# Each lon segment in a given lat is equal area, so mean() across lon's weights them evenly\n",
    "# Months are all averaged into a single year before linregress because intra-year seasonality can create spurious trends\n",
    "dfr = linr(rgrid.groupby(['year', 'lat', 'lon']).mean().groupby(['year', 'lat']).mean()) # avg the lon's and month's, then linregress.\n",
    "dfl = linr(lgridd.groupby(['year', 'lat', 'lon']).mean().groupby(['year', 'lat']).mean()) \n",
    "dflg = linr(lgriddg.groupby(['year', 'lat', 'lon']).mean().groupby(['year', 'lat']).mean())\n",
    "dflm = linr(lgriddm.groupby(['year', 'lat', 'lon']).mean().groupby(['year', 'lat']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for joint grids 1 & 2\n",
    "\n",
    "# Warning: 19 years uses 4+ GB memory and can crash as non-addressable. \n",
    "# This is why it converts float64 to float32 (saves ~15% mem)\n",
    "yr1 = 2003\n",
    "yr2 = 2021\n",
    "wn1 = 649.0\n",
    "wn2 = 1650.0\n",
    "\n",
    "ljoint = lgridd.loc[:, wn1:wn2].loc[yr1:yr2].astype('float32')\n",
    "ljoint = mlma(ljoint.T, wn[(wn['wavenumber'] >=wn1) & (wn['wavenumber'] < wn2)]).T.astype('float32')\n",
    "rjoint = rgrid.loc[:, wn1:wn2].loc[yr1:yr2].astype('float32')\n",
    "for i in rjoint.columns.values:\n",
    "    rjoint.loc[(rjoint[i] <= 0), i] = np.nan\n",
    "rjoint = rjoint.rename_axis('wavenumber', axis='columns')\n",
    "\n",
    "jg1 = pd.DataFrame(ljoint.stack(), columns = ['LBL']).rename_axis(['year', 'month', 'lat', 'lon', 'wavenumber']).join(\n",
    "    pd.DataFrame(rjoint.stack(dropna = False), columns = ['AIRS']), \n",
    "    how='left')\n",
    "\n",
    "ljoint = dfl.loc[:, wn1:wn2]\n",
    "ljoint = mlma(ljoint.T, wn[(wn['wavenumber'] >=wn1) & (wn['wavenumber'] < wn2)]).T\n",
    "rjoint = dfr.loc[:, wn1:wn2]\n",
    "for i in rjoint.columns.values:  # Remove a handful of extreme outliers, usually due to incomplete timeseries\n",
    "    rjoint.loc[(rjoint[i] > 1.75), i] = np.nan\n",
    "    rjoint.loc[(rjoint[i] < -1.75), i] = np.nan\n",
    "\n",
    "jg2 = pd.DataFrame(ljoint.stack(), columns = ['LBL']).rename_axis(['lat', 'wavenumber']).join(\n",
    "    pd.DataFrame(rjoint.stack(dropna = False), columns = ['AIRS']).rename_axis(['lat', 'wavenumber']), \n",
    "    how='left')\n",
    "jg2 = jg2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jgp(df, save, savename):\n",
    "    sns.set_theme(style=\"ticks\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(2, 1.5))    \n",
    "    g = sns.JointGrid(data=df, x=\"AIRS\", y=\"LBL\", marginal_ticks=True)\n",
    "\n",
    "    # Create an inset legend for the histogram colorbar\n",
    "    cax = g.fig.add_axes([.15, .55, .02, .2])\n",
    "\n",
    "    # Add the joint and marginal histogram plots\n",
    "    g.plot_joint(\n",
    "        sns.histplot, #discrete=(True, False),\n",
    "        cmap=\"magma_r\", pmax = .9, cbar=True, cbar_ax=cax  # cmap=\"light:#03012d\"\n",
    "    )\n",
    "    \n",
    "    # Plot y=x line\n",
    "    ax = g.ax_joint\n",
    "    ax.plot(ax.get_xlim(), ax.get_xlim(), ls=\":\", lw=1, alpha=0.6, label=\"1:1\")\n",
    "    if savename == 'f':\n",
    "        delta = ' rate of change'\n",
    "        delta1 = 'yr$^{-1}$'\n",
    "    else:\n",
    "        delta = ''\n",
    "        delta1 = ''\n",
    "    ax.set_xlabel('AIRS Radiance'+delta+', mW$\\,$m$^{-2}$(cm$^{-1}$)$^{-1}$sr$^{-1}$'+delta1)\n",
    "    ax.set_ylabel('LBL Radiance'+delta+', mW$\\,$m$^{-2}$(cm$^{-1}$)$^{-1}$sr$^{-1}$'+delta1)\n",
    "                \n",
    "    g.plot_marginals(sns.histplot, element=\"step\", color=\"#03012d\")\n",
    "    \n",
    "    # Histograms acquire different max values, making their apparent shapes slightly different.\n",
    "    # Intervene and force the same y-max on both:\n",
    "    marg_max = max(g.ax_marg_x.get_ylim()[1], g.ax_marg_y.get_xlim()[1])\n",
    "    ax = g.ax_marg_x\n",
    "    ax.set_ylim(0, marg_max)\n",
    "    ax = g.ax_marg_y\n",
    "    ax.set_xlim(0, marg_max)\n",
    "        \n",
    "    plt.figtext(0.9, .9, savename, ha = 'right', fontsize = 30)\n",
    "    \n",
    "    if save:\n",
    "        g.savefig('.\\fig2'+savename+'.png')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', round((len(jg1)/1E6), 1), 'million monthly avg radiances in jg1')\n",
    "print('There are', round((len(jg2)/1E3), 1), 'thousand monthly avg radiances in jg2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jgp(jg1, False, 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jgp(jg2, False, 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 16)) #constrained_layout=True,\n",
    "num = 6\n",
    "ax = [None]*(num + 1)\n",
    "\n",
    "gs = GridSpec(8, 11)\n",
    "ax[0] = fig.add_subplot(gs[0, :])\n",
    "ax[1] = fig.add_subplot(gs[1, :])\n",
    "ax[2] = fig.add_subplot(gs[2, :])\n",
    "ax[3] = fig.add_subplot(gs[3, :])\n",
    "ax[4] = fig.add_subplot(gs[3:, :5])\n",
    "ax[5] = fig.add_subplot(gs[3:, 6:])\n",
    "\n",
    "ax[0].plot(globalr[:1136.634].index, globalr[:1136.634].values, color = 'black')\n",
    "ax[0].plot(globalr[1137:].index, globalr[1137:].values, color = 'black', label = 'AIRS')\n",
    "ax[0].plot(globall.index, globall.values, color = 'blue', label = 'LBL')\n",
    "\n",
    "leg = ax[0].legend()\n",
    "\n",
    "ax[1].plot(dfr.T.index[:130], (dfr.T * weights).T.sum().values[:130], color = 'black',  label = 'AIRS')\n",
    "ax[1].plot(dfr.T.index[131:1083], (dfr.T * weights).T.sum().values[131:1083], color = 'black', label = 'AIRS')\n",
    "ax[1].plot(dfr.T.index[1084:], (dfr.T * weights).T.sum().values[1084:], color = 'black', label = '_')\n",
    "ax[1].plot(dfl.T.index, (dfl.T * weights).T.sum().values, color = 'blue', label = 'LBL')\n",
    "ax[2].plot((dflm.T*weights).T.sum().index, (dflm.T*weights).T.sum().values, color = 'blue')\n",
    "ax[3].plot((dflg.T*weights).T.sum().index, (dflg.T*weights).T.sum().values, color = 'blue')\n",
    "\n",
    "ax[0].set_ylabel(r'Radiance, mW$\\,$m$^{-2}$(cm$^{-1}$)$^{-1}$sr$^{-1}$')\n",
    "ax[2].set_ylabel(r'Radiance rate of change, mW$\\,$m$^{-2}$(cm$^{-1}$)$^{-1}$sr$^{-1}$yr$^{-1}$')\n",
    "ax[3].set_xlabel(r'Wavenumber, cm$^{-1}$')\n",
    "\n",
    "for n in np.arange(1, 4, 1):\n",
    "    ax[n].axhline(0, color='black', linestyle='--')\n",
    "\n",
    "img1 = plt.imread(\"fig2e.png\")\n",
    "ax[4].imshow(img1)\n",
    "ax[4].axis('off')\n",
    "\n",
    "img2 = plt.imread(\"fig2f.png\")\n",
    "ax[5].imshow(img2)\n",
    "ax[5].axis('off')\n",
    "\n",
    "if 1 == 2:\n",
    "    plt.savefig('fig2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = ['70°S to 50°S', '50°S to 30°S', '30°S to 10°S', '10°S to 10°N', \n",
    "        '10°N to 30°N', '30°N to 50°N', '50°N to 70°N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 7\n",
    "fig = plt.figure()\n",
    "gs = gridspec.GridSpec(nrows=num, ncols=1, figure=fig, height_ratios= [1]*num)\n",
    "ax = [None]*(num + 1)\n",
    "\n",
    "for i in range(num):\n",
    "    n = num-i+1\n",
    "    ax[i] = fig.add_subplot(gs[i])\n",
    "    ax[i].axhline(0, color='black')\n",
    "    \n",
    "    ax[i].plot(dfl.loc[n].index, dfl.loc[n].values, color = 'blue', label = 'LBL')\n",
    "    ax[i].plot(dfr.loc[n].index[:1083], dfr.loc[n].values[:1083], color = 'black', label = 'AIRS')\n",
    "    ax[i].plot(dfr.loc[n].index[1084:], dfr.loc[n].values[1084:], color = 'black', label = 'AIRS')\n",
    "    ax[i].annotate(lats[n-2], (1450, -0.1), color='black')\n",
    "\n",
    "ax[3].set_ylabel(r'Radiance rate of change, mW$\\,$m$^{-2}$(cm$^{-1}$)$^{-1}$sr$^{-1}$yr$^{-1}$')\n",
    "ax[i].set_xlabel(r'Wavenumber, cm$^{-1}$')\n",
    "\n",
    "if 1 == 2:\n",
    "    plt.savefig('fig3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4 Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 710 # cm-1, lower bound\n",
    "c2 = 720 # cm-1, upper bound\n",
    "path_compare = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Fig 4 AIRS histogram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5 = pd.DataFrame()\n",
    "for month in np.arange(1, 13, 1):\n",
    "    for lon in np.arange(1, 19, 1):\n",
    "        try:\n",
    "            test = linr(rgrid.loc[:, c1:c2].loc[:, month, :, lon]).rename_axis(['lat'])\n",
    "            test['lon'] = lon\n",
    "            test['month'] = month\n",
    "            test.set_index(['lon', 'month'], append=True, inplace = True)\n",
    "            p5 = p5.append(test)\n",
    "        except:\n",
    "            pass\n",
    "p5.sort_index(inplace = True)\n",
    "p5o = pd.DataFrame(index = p5.index, columns = ['AIRS'], dtype='float')\n",
    "\n",
    "for row in p5.iterrows():\n",
    "    p5o.loc[row[0][0], row[0][1], row[0][2]]['AIRS'] = scipy.integrate.trapz(row[1].values, row[1].index.values)\n",
    "p5om = p5o.groupby(['lat']).mean()\n",
    "path_compare = pd.concat([path_compare, p5om], axis=1)\n",
    "path_compare.rename_axis(['lat'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare LBL Fig. 4 histogram Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5l = pd.DataFrame()\n",
    "for month in np.arange(1, 13, 1):\n",
    "    for lon in np.arange(1, 19, 1):\n",
    "        try:\n",
    "            test = linr(lgridd.loc[:, c1:c2].loc[:, month, :, lon]).rename_axis(['lat'])\n",
    "            test['lon'] = lon\n",
    "            test['month'] = month\n",
    "            test.set_index(['lon', 'month'], append=True, inplace = True)\n",
    "            p5l = p5l.append(test)\n",
    "        except:\n",
    "            pass\n",
    "p5l.sort_index(inplace = True)\n",
    "p5lo = pd.DataFrame(index = p5l.index, columns = ['LBL'], dtype='float')\n",
    "\n",
    "for row in p5l.iterrows():\n",
    "    p5lo.loc[row[0][0], row[0][1], row[0][2]]['LBL'] = scipy.integrate.trapz(row[1].values, row[1].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5hist = pd.concat([p5o*years, p5lo*years], axis=1)\n",
    "palette = {\"AIRS\":\"tab:grey\",\n",
    "           \"LBL\":\"tab:blue\"}\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax = sns.histplot(data=p5hist.melt(), x=\"value\", hue=\"variable\", element=\"step\", palette = palette, stat='density')\n",
    "ax.set_xlabel('Radiant flux [mW$\\,$m$^{-2}$sr$^{-1}$]')\n",
    "ax.axvline((p5hist.groupby(['lat', 'month']).mean().groupby(['lat']).mean().T* weights).sum(axis=1)['AIRS'], color='k', alpha=0.4, lw=2)\n",
    "ax.axvline((p5hist.groupby(['lat', 'month']).mean().groupby(['lat']).mean().T* weights).sum(axis=1)['LBL'], color='b', alpha = 0.4, lw=2)\n",
    "if 1 == 2:\n",
    "    plt.savefig('fig4b.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other pathways (not used, preservation only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathway 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1o = pd.DataFrame(index = np.arange(2, 9, 1), columns = ['Pathway 1'])\n",
    "p1 = linr(rgrid.loc[:, c1:c2].groupby(['year', 'lat', 'lon']).mean().groupby(['year', 'lat']).mean())\n",
    "for lat in np.arange(2, 9, 1):\n",
    "    p1o.loc[lat]['Pathway 1'] = scipy.integrate.trapz(p1.loc[lat].values, p1.loc[lat].index.values)\n",
    "path_compare = pd.concat([path_compare, p1o], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathway 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2o = pd.DataFrame(index = np.arange(2, 9, 1), columns = ['Pathway 2'])\n",
    "p2 = pd.DataFrame()\n",
    "for lon in np.arange(1, 19, 1):\n",
    "    test = linr(rgrid.loc[:, c1:c2].groupby(['year', 'lat', 'lon']).mean().loc[:, :, lon]).rename_axis(['lat'])\n",
    "    #test = test.rename_axis(['lat'])\n",
    "    test['lon'] = lon\n",
    "    test.set_index(['lon'], append=True, inplace = True)\n",
    "    p2 = p2.append(test)\n",
    "p2 = p2.groupby(['lat']).mean()\n",
    "for lat in np.arange(2, 9, 1):\n",
    "    p2o.loc[lat]['Pathway 2'] = scipy.integrate.trapz(p2.loc[lat].values, p2.loc[lat].index.values)\n",
    "path_compare = pd.concat([path_compare, p2o], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathway 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3o = pd.DataFrame(index = np.arange(2, 9, 1), columns = ['Pathway 3'])\n",
    "p3 = pd.DataFrame()\n",
    "for month in tqdm(np.arange(1, 13, 1)):\n",
    "    for lon in np.arange(1, 19, 1):\n",
    "        try:\n",
    "            test = linr(rgrid.loc[:, c1:c2].loc[:, month, :, lon]).rename_axis(['lat'])\n",
    "            test['lon'] = lon\n",
    "            test['month'] = month\n",
    "            test.set_index(['lon', 'month'], append=True, inplace = True)\n",
    "            p3 = p3.append(test)\n",
    "        except:\n",
    "            pass\n",
    "p3.sort_index(inplace = True)\n",
    "p3 = p3.groupby(['lat', 'lon']).mean().groupby(['lat']).mean()\n",
    "for lat in np.arange(2, 9, 1):\n",
    "    p3o.loc[lat]['Pathway 3'] = scipy.integrate.trapz(p3.loc[lat].values, p3.loc[lat].index.values)\n",
    "path_compare = pd.concat([path_compare, p3o], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathway 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4o = pd.DataFrame(index = np.arange(2, 9, 1), columns = ['Pathway 4'])\n",
    "p4 = pd.DataFrame()\n",
    "for month in tqdm(np.arange(1, 13, 1)):\n",
    "    for lon in np.arange(1, 19, 1):\n",
    "        try:\n",
    "            test = linr(rgrid.loc[:, c1:c2].loc[:, month, :, lon]).rename_axis(['lat'])\n",
    "            test['lon'] = lon\n",
    "            test['month'] = month\n",
    "            test.set_index(['lon', 'month'], append=True, inplace = True)\n",
    "            p4 = p4.append(test)\n",
    "        except:\n",
    "            pass\n",
    "p4.sort_index(inplace = True)\n",
    "p4 = p4.groupby(['lat', 'month']).mean().groupby(['lat']).mean()\n",
    "for lat in np.arange(2, 9, 1):\n",
    "    p4o.loc[lat]['Pathway 4'] = scipy.integrate.trapz(p4.loc[lat].values, p4.loc[lat].index.values)\n",
    "path_compare = pd.concat([path_compare, p4o], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intgrls = {}\n",
    "\n",
    "intgrls['Observed'] = scipy.integrate.trapz((dfr.loc[:, c1:c2].T*weights).T.sum().values, dfr.loc[:, c1:c2].T.index)*years\n",
    "intgrls['Simulated'] = scipy.integrate.trapz((dfl.loc[:, c1:c2].T*weights).T.sum().values, dfl.loc[:, c1:c2].T.index)*years\n",
    "intgrls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfc11 = (lcfc11.groupby(['lat', 'lon']).mean().groupby(['lat']).mean().T * weights).T.sum() - (lcfc0.groupby(['lat', 'lon']).mean().groupby(['lat']).mean().T * weights).T.sum().loc[:1600]\n",
    "cfc12 = (lcfc12.groupby(['lat', 'lon']).mean().groupby(['lat']).mean().T * weights).T.sum() - (lcfc0.groupby(['lat', 'lon']).mean().groupby(['lat']).mean().T * weights).T.sum().loc[:1600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "gs = gridspec.GridSpec(nrows=num, ncols=1, figure=fig, height_ratios= [1]*num)\n",
    "ax = [None]*(num + 1)\n",
    "\n",
    "for n in range(num):\n",
    "    ax[n] = fig.add_subplot(gs[n])\n",
    "    ax[n].set_xlim(780, 999)\n",
    "    ax[n].set_ylim(-0.045, 0.055)\n",
    "    ax[n].axhline(0, color='black')\n",
    "\n",
    "ax[0].plot(dfr.T.index, (dfr.T * weights).T.sum().values, color = 'black', label = 'AIRS')\n",
    "ax[0].plot(dfl.T.index, (dfl.T * weights).T.sum().values, color = 'blue', label = 'LBL')\n",
    "\n",
    "ax[1].plot((dflg.T*weights).T.sum().index, (dflg.T*weights).T.sum().values, color = 'blue')\n",
    "\n",
    "ax[1].set_ylabel(r'Radiance rate of change, mW$\\,$m$^{-2}$(cm$^{-1}$)$^{-1}$sr$^{-1}$yr$^{-1}$')\n",
    "ax[2].set_xlabel(r'Wavenumber, cm$^{-1}$')\n",
    "\n",
    "ax[2].plot(cfc11.index, cfc11.values/years, lw=0.75, label='CFC-11', color = 'red')\n",
    "ax[2].plot(cfc12.index, cfc12.values/years, lw=0.75, label='CFC-12', color = 'green')\n",
    "ax[2].legend()\n",
    "\n",
    "if 1 == 2:\n",
    "    plt.savefig('FIG-S4.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rloc = pd.DataFrame()\n",
    "for year in np.arange(2003, 2022, 1):\n",
    "    rloci = pd.DataFrame()\n",
    "    files = glob.glob('C:\\\\data\\\\location\\\\'+str(year)+'\\\\*.csv')\n",
    "    if len(files) != 12:\n",
    "        print(len(files), 'files found, instead of 12')\n",
    "    for file in files:\n",
    "        rloci = rloci.append(pd.read_csv(file))\n",
    "    try:\n",
    "        rloci = rloci.drop(['sci'], axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    rloci = rloci.set_index(['time'])\n",
    "    rloci = rloci.astype('float16')\n",
    "    rloc = rloc.append(rloci)\n",
    "    print(f'Year {year} done. Memory use:', round(rloc.memory_usage().sum()/2**20, 1), 'MB')\n",
    "\n",
    "rloci = []\n",
    "if rloc.isnull().values.any():\n",
    "    print('nan detected in final rloc dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import (LongitudeFormatter, LatitudeFormatter,\n",
    "                                LatitudeLocator)\n",
    "\n",
    "xedges = np.linspace(-180,180,181)\n",
    "yedges = np.linspace(-90,90,91)\n",
    "\n",
    "fig = plt.figure(figsize=(18, 20), constrained_layout=True)\n",
    "gs0 = fig.add_gridspec(7, 3)\n",
    "\n",
    "for a in range(7):\n",
    "    for b in range(3):\n",
    "        year = 2003 + 3 * a + b\n",
    "        if year > 2021:\n",
    "            break\n",
    "        print(\"processing \"+str(year)+\"...\")\n",
    "        ax = fig.add_subplot(gs0[a, b], projection=ccrs.EqualEarth())\n",
    "        ax.coastlines()\n",
    "        ax.set_global()\n",
    "        rloc2 = rloc.loc[str(year)+'-01-01':str(year+1)+'-01-01']\n",
    "        x = rloc2['lon'].values\n",
    "        y = rloc2['lat'].values\n",
    "        H, xedges, yedges = np.histogram2d(x, y, bins=(xedges, yedges))\n",
    "        H = H.T  # Let each row list bins with common y range.\n",
    "        cf = ax.pcolormesh(xedges, yedges, H, transform=ccrs.PlateCarree(), vmax = 2000, cmap='magma_r') \n",
    "        ax.set_title(str(year))\n",
    "        gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.25, color='black', alpha=0.5)\n",
    "        gl.ylocator = mticker.FixedLocator(np.arange(-90, 91, 20))\n",
    "        gl.xlocator = mticker.FixedLocator(np.arange(-180, 181, 20))\n",
    "        gl.xformatter = LongitudeFormatter()\n",
    "        gl.yformatter = LatitudeFormatter()\n",
    "ax = fig.add_subplot(gs0[6, 1])\n",
    "ax.axis('off')\n",
    "ax.annotate('Count', (0.4, 0.11), color='black', fontsize=18)\n",
    "fig.colorbar(cf, ax=ax, location='bottom')\n",
    "if 1 == 2:\n",
    "    plt.savefig('FIG-S5.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the result here consistent with 0.53 W/m2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (dflg.T*weights).T.sum()\n",
    "check = scipy.integrate.trapz(df[:1000].values, df[:1000].index.values) * 19 * np.pi / 1000\n",
    "print('The LBL integral for 0.1 to 1000 cm-1 is', round(check, 3), 'W/m2, which is', round((check/-0.53*100), 1), 'percent of 0.53 W/m2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
